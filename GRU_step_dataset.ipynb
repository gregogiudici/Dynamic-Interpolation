{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"sX_TCZCxYvol"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import signal\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","import random\n","\n","if torch.cuda.is_available():\n","  dev = 'cuda'\n","  print(\"Cuda avaiable. Device used to train the model:\", dev)\n","else: \n","  dev = 'cpu'\n","  print(\"Cuda not avaiable. Device used to train the model:\", dev)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"d7b5d1ab"},"source":["# **A harmonic series dataset**\n","\n","This dataset generates a periodic wave given a harmonic distribution and a number of cycles we want to compute."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d4baf19"},"outputs":[],"source":["# First version of HarmonicSeriesDataset (from: sequential_things.ipynb by Franco Caspe)\n","class HarmonicSeriesDataset(Dataset):\n","    \n","    def __init__(self, harmonics,n_periods=1):\n","        self.harmonics = torch.tensor(harmonics)\n","        self.len = n_periods*2*harmonics.size()[0]\n","        self.sample_rate = 2*harmonics.size()[0]\n","        n_freqs = harmonics.size()[0]\n","        self.phases = torch.zeros(n_freqs)\n","        self.freqs = torch.linspace(start=0, end=n_freqs-1, steps=n_freqs)\n","    \n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","        sample = 0\n","        self.phases += 2*np.pi*self.freqs/self.sample_rate\n","        sample = torch.sum(self.harmonics*torch.sin(self.phases))\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4w9PhXWsRCh"},"outputs":[],"source":["# Second version of HarmonicSeriesDataset\n","class HarmonicSeriesDataset(Dataset):\n","    \n","    def __init__(self, harmonics,n_periods=1):\n","        self.harmonics = torch.tensor(harmonics)\n","        self.len = n_periods*2*harmonics.size()[0]\n","        self.sample_rate = 2*harmonics.size()[0]\n","        self.n_freqs = harmonics.size()[0]\n","        self.phases = torch.zeros(self.n_freqs)\n","        self.freqs = torch.linspace(start=0, end=self.n_freqs-1, steps=self.n_freqs)\n","    \n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","      self.phases[:] = 0\n","      check = np.random.choice([True,False])\n","      input = torch.ones(self.len) if(check) else torch.zeros(self.len)\n","      # delay = np.random.randint(0,self.len-2)\n","      d_1 = np.random.randint(0,self.len/2)\n","      d_2 = np.random.randint(self.len/2,self.len-2)\n","      input[d_1:d_2] = 0 if(check) else 1\n","      #input[0:delay] = 0\n","      output = torch.zeros(self.len)\n","      \n","      for i in range(self.len):   \n","        self.phases += (2*np.pi*self.freqs/self.sample_rate)\n","        self.phases = self.phases * input[i]\n","        output[i] = torch.sum(self.harmonics*torch.sin(self.phases))*input[i]    \n","      return input, output"]},{"cell_type":"markdown","metadata":{"id":"6ec8bdb7"},"source":["Let's generate a dataset and plot its content."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56afb2bd"},"outputs":[],"source":["# Dataset configuration\n","period_len = 60\n","n_periods = 4\n","# Generate a distribution of harmonics\n","harmonics = torch.zeros(period_len//2)\n","harmonics[1] = 1\n","harmonics[2] = 1\n","harmonics[3] = 1\n","harmonics[10] = 1\n","# Normalize distribution\n","harmonics = harmonics/torch.sum(harmonics)\n","\n","# Create dataset\n","batch_size = 128\n","dataset = HarmonicSeriesDataset(harmonics,n_periods)\n","train_dataloader = torch.utils.data.DataLoader(dataset)\n","\n","# Sample storage to plot\n","signal_len = len(train_dataloader)\n","print(period_len*n_periods)\n","print(signal_len)\n","\n","samples = torch.zeros(batch_size,signal_len,2)\n","\n","#for i,sample in enumerate(dataloader):\n","#      samples[:,i] = sample\n","\n","for i in range(batch_size):\n","  samples[i,:,0],samples[i,:,1] = next(iter(train_dataloader))\n","\n","\n","print(\"Samples.shape:\",samples.shape)\n","for i in range(5):\n","  plt.plot(samples[i,:,0].detach().numpy())\n","  plt.plot(samples[i,:,1].detach().numpy())\n","  plt.title(\"Input and Output {}\".format(i))\n","  plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9be3ea08"},"source":["\n","# **Dataset Example.** "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1674839512524,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"c0209b72","outputId":"b7b030e6-5995-40b0-86dc-5e0c855d1d39"},"outputs":[],"source":["train_samples = samples\n","print(train_samples.shape)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(train_samples[0,:,:].detach().cpu().numpy())\n","plt.title(\"Test Samples\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dXBe9RfFjL1p"},"source":["# **Gated Recurrent Unit (GRU)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6GvDuLujSN3"},"outputs":[],"source":["class GRUmodel(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, num_layers=1):\n","    super(GRUmodel, self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_dim = hidden_dim\n","    # GRU (input)\n","    self.gru = nn.GRU(input_size, hidden_dim, num_layers=num_layers, batch_first=True)\n","    # Fully connected (output)\n","    self.lin = nn.Linear(hidden_dim, output_size)\n","    \n","  # Forward method\n","  def forward(self, seq):\n","\n","    input = seq  # input.shape = (N,L,input_size)\n","    \n","    out, hidden = self.gru(input) # out.shape = (L,hidden_dim)...hidden.shape = (num_layers, hidden_dim)\n","    out = self.lin(out) # out.shape = (1,1)\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us6NDKk_zbPL"},"outputs":[],"source":["def gru_evaluate_on_data(net, eval_input, target, device, plot=False):\n","\n","  L = target.shape[1] # sequence length\n","  batch_size = target.shape[0] # batch size\n","  random = np.random.randint(0,batch_size-2)\n","  target = target[random,:,:].unsqueeze(0).to(device) # ([N,L,1])\n","  # seq = torch.ones([batch_size,L,1]).to(device) # ([N,L,1])\n","  seq = eval_input[random,:,:].unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    pred = net(seq)\n","      # Calculate evaluation loss\n","  eval_loss = torch.sum(torch.abs(target-pred))\n","\n","  # Plotting results\n","  if(plot):\n","    fig, ax = plt.subplots()\n","    print(\"[TEST ON DATA] Eval loss {}\".format(eval_loss))\n","    ax.plot(seq[0,:,:].detach().cpu().numpy())\n","    ax.plot(target[0,:,:].detach().cpu().numpy())\n","    ax.plot(pred[0,:,:].detach().cpu().numpy())\n","    plt.show()\n","\n","  return eval_loss\n","  \n","def gru_train(net, epochs, train_samples, device):\n","  \n","  net.train()\n","\n","  # Define Loss, Optimizer, ecc.\n","  criterion = nn.L1Loss()\n","  optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","  best_eval_loss = np.inf\n","\n","  target = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1])\n","  train = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1]) \n","  L = target.shape[1] # sequence length\n","  n_batches = target.shape[0] # batch size\n","  epochs_loss = np.zeros(epochs)\n","\n","  for epoch in range(epochs): \n","    optimizer.zero_grad()\n","    running_loss = 0.0\n","    # seq = torch.ones([n_batches,L,1]).to(device) # ([N,L,1])\n","    seq = train_samples[:,:,0].unsqueeze(2).to(device)\n","    prediction = net(seq)\n","    loss = criterion(prediction, target) # Calculate loss\n","    loss.backward() # Backpropagation and calculates gradients\n","    optimizer.step() # Updates the weights\n","    # Print statistics\n","    running_loss += loss.item() # To calculate epochs' mean loss\n","    plot = True if (epoch%(epochs/16)==0) else False\n","    eval_loss = gru_evaluate_on_data(net, seq, target, device, plot=plot)\n","    \n","    epochs_loss[epoch] = eval_loss # For plotting loss during epochs\n","\n","    if eval_loss < best_eval_loss:\n","      best_eval_loss = eval_loss\n","      torch.save(net.state_dict(), 'best_gru.pt')\n","\n","    if (epoch%(epochs/20) == 0):\n","        print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n","        print(\"Train Loss: {:.4f} - Best Eval {:.4f}\".format(running_loss, best_eval_loss))\n","    \n","    running_loss = 0.0\n","\n","  print(\"---------- FINISHED TRAINING ----------\")\n","\n","  # Print Eval Loss\n","  x_ = np.linspace(0, epochs-1, epochs)\n","  y_ = epochs_loss\n","  yhat_ = signal.savgol_filter(y_, 101, 3) # Savitzky-Golay filter for smoothing\n","\n","  fig, ax = plt.subplots()\n","  ax.plot(x_, y_)\n","  ax.plot(x_, yhat_)\n","  ax.set_xlabel('Epochs')\n","  ax.set_ylabel('Eval Loss') \n","  # ax.grid(True) \n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IfZZfcnFhZU"},"outputs":[],"source":["def train_and_test_GRU(hidden_size, n_hidden_layers, train_data, target, epochs, device):\n","  train_len = train_data.size()[2]\n","\n","  net = GRUmodel(1,1,hidden_size, n_hidden_layers)\n","  net = net.to(device)\n","\n","  model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n","  params = sum([np.prod(p.size()) for p in model_parameters])\n","  print(\"[INFO] Number of parameters: {}\".format(params))\n","  \n","  # TRAINING\n","  gru_train(net, epochs, train_samples, device)\n","\n","  # TEST\n","  net.load_state_dict(torch.load('best_gru.pt'))  \n","  net.eval()\n","  target = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1])\n","  input = train_samples[:,:,0].unsqueeze(2).to(device)\n","  gru_evaluate_on_data(net, input, target, device, plot=True)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2m9ScccH6Hx"},"outputs":[],"source":["GRUnet = train_and_test_GRU(hidden_size=64, n_hidden_layers=1, train_data=train_samples, target=train_samples, epochs=5000, device=dev)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Testing Trained GRUnet**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1674840634352,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"Zg9nEOnczcCu","outputId":"c79dbae4-b310-4028-e5de-9246a22da60e"},"outputs":[],"source":["seq = torch.ones(1,960,1)\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()\n","\n","seq = torch.ones(1,960,1)\n","seq[:,55:120,:] = 0\n","seq[:,360:480,:] = 0\n","seq[:,720:959,:] = 0\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":2887,"status":"ok","timestamp":1674840644556,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"BaWCDrU5-KI1","outputId":"60b9a585-e199-4094-a78c-2d1cd29de393"},"outputs":[],"source":["seq = torch.ones(1,2048,1)\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()\n","\n","seq = torch.ones(1,2048,1)\n","seq[:,120:240,:] = 1\n","seq[:,1024:2000,:] = 1\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO7GsaoKioDTwn57AETeOfj","provenance":[]},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"51a1e27a7986eee058d319d028d75df63f805ad76db200a802ec4ff9ece56162"}}},"nbformat":4,"nbformat_minor":0}
