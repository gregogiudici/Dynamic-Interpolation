{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9995,"status":"ok","timestamp":1675353689684,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"sX_TCZCxYvol","outputId":"ee5718c1-f0ef-45a4-e8d9-a87090b66eb2"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import signal\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","import random\n","\n","if torch.cuda.is_available():\n","  dev = 'cuda'\n","  print(\"Cuda avaiable. Device used to train the model:\", dev)\n","else: \n","  dev = 'cpu'\n","  print(\"Cuda not avaiable. Device used to train the model:\", dev)\n"]},{"cell_type":"markdown","metadata":{"id":"d7b5d1ab"},"source":["# **A harmonic series dataset**\n","\n","This dataset generates an input signal and an output signal, given a harmonic distribution and a number of cycles we want to compute.\\\n","Input = ramp signal\\\n","Ouput = harmonic wave"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w4w9PhXWsRCh"},"outputs":[],"source":["# Third version of HarmonicSeriesDataset\n","class HarmonicSeriesDataset(Dataset):\n","    \n","    def __init__(self, harmonics,n_periods=1):\n","        self.harmonics = torch.tensor(harmonics)\n","        #self.len = n_periods*2*harmonics.size()[0]\n","        self.sequence_len = n_periods*2*harmonics.size()[0]\n","        self.sample_rate = 2*harmonics.size()[0]\n","        self.sample_time = 1/(2*harmonics.size()[0])\n","        self.n_freqs = harmonics.size()[0]\n","        self.phases = torch.zeros(self.n_freqs)\n","        self.freqs = torch.linspace(start=0, end=self.n_freqs-1, steps=self.n_freqs)\n","    \n","    def __len__(self):\n","        return 100\n","\n","    def __getitem__(self, idx):\n","      self.phases[:] = 0\n","      check = np.random.choice([True,False])\n","      on_off = torch.ones(self.len) if(check) else torch.zeros(self.len)\n","      # delay = np.random.randint(0,self.len-2)\n","      d_1 = np.random.randint(0,self.len/2)\n","      d_2 = np.random.randint(self.len/2,self.len-2)\n","      on_off[d_1:d_2] = 0 if(check) else 1\n","      #input[0:delay] = 0\n","      input = torch.zeros(self.len)\n","      output = torch.zeros(self.len)\n","      \n","      for i in range(self.len):  \n","        if i == 0:\n","          input[i] = self.sample_time if on_off[i] else 0\n","        else:\n","          input[i] = input[i-1] + self.sample_time if on_off[i] else 0\n","        \n","        # Clip input from 0 to 1\n","        input[i] = input[i].clip(0,1)\n","\n","        self.phases += (2*np.pi*self.freqs/self.sample_rate)\n","        self.phases = self.phases * on_off[i]\n","        output[i] = torch.sum(self.harmonics*torch.sin(self.phases))*input[i]\n","\n","      return input, output"]},{"cell_type":"markdown","metadata":{"id":"6ec8bdb7"},"source":["Let's generate a dataset and plot its content."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2526,"status":"ok","timestamp":1675353702344,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"56afb2bd","outputId":"124e68f6-493b-49f4-fe3e-6cb81b36b50b"},"outputs":[],"source":["# Dataset configuration\n","period_len = 60\n","n_periods = 4\n","# Generate a distribution of harmonics\n","harmonics = torch.zeros(period_len//2)\n","harmonics[1] = 1\n","harmonics[2] = 1\n","harmonics[3] = 1\n","harmonics[10] = 1\n","# Normalize distribution\n","harmonics = harmonics/torch.sum(harmonics)\n","\n","# Create dataset\n","batch_size = 60\n","dataset = HarmonicSeriesDataset(harmonics,n_periods)\n","train_dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size)\n","\n","# Sample storage to plot\n","signal_len = len(train_dataloader)\n","print(period_len*n_periods)\n","print(signal_len)\n","\n","# Examples of dataset\n","samples = torch.zeros(batch_size,period_len*n_periods,2)\n","\n","samples[:,:,0],samples[:,:,1] = next(iter(train_dataloader))\n","\n","\n","print(\"Samples.shape:\",samples.shape)\n","for i in range(5):\n","  plt.plot(samples[i,:,0].detach().numpy())\n","  plt.plot(samples[i,:,1].detach().numpy())\n","  plt.title(\"Input and Output {}\".format(i))\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"9be3ea08"},"source":["# **Dataset Example.** \n","\n","Let's generate a dataset for the models to predict an output $A$ samples ahead."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1675353768836,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"c0209b72","outputId":"aa06b6fe-773c-464c-eaed-85041c645e93"},"outputs":[],"source":["print(samples.shape)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(samples[0,:,:].detach().cpu().numpy())\n","# ax.plot(test_samples.view(-1).detach().cpu().numpy())\n","plt.title(\"Test Samples\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dXBe9RfFjL1p"},"source":["# **Gated Recurrent Unit (GRU)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6GvDuLujSN3"},"outputs":[],"source":["class GRUmodel(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, num_layers=1):\n","    super(GRUmodel, self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_dim = hidden_dim\n","    # GRU (input)\n","    self.gru = nn.GRU(input_size, hidden_dim, num_layers=num_layers, batch_first=True)\n","    # Fully connected (output)\n","    self.lin = nn.Linear(hidden_dim, output_size)\n","    \n","  # Forward method\n","  def forward(self, seq):\n","\n","    input = seq  # input.shape = (N,L,input_size)\n","    \n","    out, hidden = self.gru(input) # out.shape = (L,hidden_dim)...hidden.shape = (num_layers, hidden_dim)\n","    out = self.lin(out) # out.shape = (1,1)\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us6NDKk_zbPL"},"outputs":[],"source":["def gru_evaluate_on_data(net, eval_input, target, device, plot=False):\n","\n","  L = target.shape[1] # sequence length\n","  batch_size = target.shape[0] # batch size\n","  random = np.random.randint(0,batch_size-2)\n","  target = target[random,:,:].unsqueeze(0).to(device) # ([N,L,1])\n","  # seq = torch.ones([batch_size,L,1]).to(device) # ([N,L,1])\n","  seq = eval_input[random,:,:].unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    pred = net(seq)\n","      # Calculate evaluation loss\n","  eval_loss = torch.sum(torch.abs(target-pred))\n","\n","  # Plotting results\n","  if(plot):\n","    fig, ax = plt.subplots()\n","    print(\"[TEST ON DATA] Eval loss {}\".format(eval_loss))\n","    ax.plot(seq[0,:,:].detach().cpu().numpy())\n","    ax.plot(target[0,:,:].detach().cpu().numpy())\n","    ax.plot(pred[0,:,:].detach().cpu().numpy())\n","    plt.show()\n","\n","  return eval_loss\n","  \n","def gru_train(net, epochs, train_dataloader, device, save_state='best_gru.pt'):\n","  \n","  net.train()\n","\n","  # Define Loss, Optimizer, ecc.\n","  criterion = nn.L1Loss()\n","  optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","  best_eval_loss = np.inf\n","\n","  # target = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1])\n","  # train = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1]) \n","  # L = target.shape[1] # sequence length\n","  # n_batches = target.shape[0] # batch size\n","  epochs_loss = np.zeros(epochs)\n","\n","  for epoch in range(epochs): \n","    optimizer.zero_grad()\n","    running_loss = 0.0\n","\n","    for i,sample in enumerate(train_dataloader):\n","      seq,target = sample\n","      target = target.unsqueeze(2).to(device)\n","      seq = seq.unsqueeze(2).to(device)\n","      prediction = net(seq)\n","      loss = criterion(prediction, target) # Calculate loss\n","      loss.backward() # Backpropagation and calculates gradients\n","      optimizer.step() # Updates the weights\n","    # Print statistics\n","    running_loss += loss.item() # To calculate epochs' mean loss\n","    plot = True if (epoch%(epochs/16)==0) else False\n","    eval_loss = gru_evaluate_on_data(net, seq, target, device, plot=plot)\n","    \n","    epochs_loss[epoch] = eval_loss # For plotting loss during epochs\n","\n","    if eval_loss < best_eval_loss:\n","      best_eval_loss = eval_loss\n","      torch.save(net.state_dict(), save_state)\n","\n","    if (epoch%(epochs/20) == 0):\n","        print('Epoch: {}/{} .............'.format(epoch, epochs), end=' ')\n","        print(\"Train Loss: {:.4f} - Best Eval {:.4f}\".format(running_loss, best_eval_loss))\n","    \n","    running_loss = 0.0\n","\n","  print(\"---------- FINISHED TRAINING ----------\")\n","\n","  # Print Eval Loss\n","  x_ = np.linspace(0, epochs-1, epochs)\n","  y_ = epochs_loss\n","  yhat_ = signal.savgol_filter(y_, 101, 3) # Savitzky-Golay filter for smoothing\n","\n","  fig, ax = plt.subplots()\n","  ax.plot(x_, y_)\n","  ax.plot(x_, yhat_)\n","  ax.set_xlabel('Epochs')\n","  ax.set_ylabel('Eval Loss') \n","  # ax.grid(True) \n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IfZZfcnFhZU"},"outputs":[],"source":["def train_and_test_GRU(hidden_size, n_hidden_layers, train_dataloader, target, epochs, device, save_state='best_gru.pt'):\n","  #train_len = train_data.size()[2]\n","\n","  net = GRUmodel(1,1,hidden_size, n_hidden_layers)\n","  net = net.to(device)\n","\n","  model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n","  params = sum([np.prod(p.size()) for p in model_parameters])\n","  print(\"[INFO] Number of parameters: {}\".format(params))\n","  \n","  # TRAINING\n","  gru_train(net, epochs, train_dataloader, device, save_state)\n","\n","  # TEST\n","  net.load_state_dict(torch.load(save_state))  \n","  net.eval()\n","  input,target = next(iter(train_dataloader))\n","  gru_evaluate_on_data(net, input, target, device, plot=True)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q2m9ScccH6Hx"},"outputs":[],"source":["GRUnet = train_and_test_GRU(hidden_size=64, n_hidden_layers=1, train_dataloader=train_dataloader, target=train_dataloader, epochs=5000, device=dev)"]},{"cell_type":"markdown","metadata":{"id":"zWWuMCdo0uly"},"source":["# **Testing Trained GRUnet**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zg9nEOnczcCu"},"outputs":[],"source":["# Testing with a random input+target from dataloader\n","seq, target = next(iter(train_dataloader))\n","batch_size = target.shape[0] # batch size\n","random = np.random.randint(0,batch_size-2)\n","\n","seq = seq[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","target = target[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","\n","# Calculate Output\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().cpu().numpy())\n","plt.plot(target[0,:,:].detach().cpu().numpy())\n","plt.plot(signal[0,:,:].detach().cpu().numpy())\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Testing Trained GRUnet**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaWCDrU5-KI1"},"outputs":[],"source":["# Testing with a random input+target from dataloader\n","seq, target = next(iter(train_dataloader))\n","batch_size = target.shape[0] # batch size\n","random = np.random.randint(0,batch_size-2)\n","\n","seq = seq[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","target = target[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","\n","# Calculate Output\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().cpu().numpy())\n","plt.plot(target[0,:,:].detach().cpu().numpy())\n","plt.plot(signal[0,:,:].detach().cpu().numpy())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Testing with a new dataset with amplitudes different from training dataset\n","amplitudes = [float(input(\"Choose input amplitude for testing dataset: \"))]\n","test_dataset = HarmonicSeriesDataset(harmonics=harmonics, n_periods=n_periods, amplitudes=amplitudes)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n","\n","seq = seq[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","target = target[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","\n","# Calculate Output\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().cpu().numpy())\n","plt.plot(target[0,:,:].detach().cpu().numpy())\n","plt.plot(signal[0,:,:].detach().cpu().numpy())\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP0MTTtDYVOxATfxWGayQXR","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.15"},"vscode":{"interpreter":{"hash":"f35544e0aba1322e325ea9e1f4852836adfddd497cc8b81102da535ed7dc4fdd"}}},"nbformat":4,"nbformat_minor":0}
