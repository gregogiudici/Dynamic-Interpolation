{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMo0DmG7JeMiGdG8ZRBqMSY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sX_TCZCxYvol","executionInfo":{"status":"ok","timestamp":1674842429404,"user_tz":-60,"elapsed":9014,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"}},"outputId":"b9f136c3-97db-4e79-c507-777d2d857c7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cuda not avaiable. Device used to train the model: cpu\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import signal\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","import random\n","\n","if torch.cuda.is_available():\n","  dev = 'cuda'\n","  print(\"Cuda avaiable. Device used to train the model:\", dev)\n","else: \n","  dev = 'cpu'\n","  print(\"Cuda not avaiable. Device used to train the model:\", dev)\n"]},{"cell_type":"markdown","metadata":{"id":"d7b5d1ab"},"source":["# **A harmonic series dataset**\n","\n","This dataset generates an input signal and an output signal, given a harmonic distribution and a number of cycles we want to compute."]},{"cell_type":"code","source":["# Second version of HarmonicSeriesDataset\n","class HarmonicSeriesDataset(Dataset):\n","    \n","    def __init__(self, harmonics,n_periods=1):\n","        self.harmonics = torch.tensor(harmonics)\n","        self.len = n_periods*2*harmonics.size()[0]\n","        self.sample_rate = 2*harmonics.size()[0]\n","        self.n_freqs = harmonics.size()[0]\n","        self.phases = torch.zeros(self.n_freqs)\n","        self.freqs = torch.linspace(start=0, end=self.n_freqs-1, steps=self.n_freqs)\n","    \n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, idx):\n","      self.phases[:] = 0\n","      check = np.random.choice([True,False])\n","      input = torch.ones(self.len) if(check) else torch.zeros(self.len)\n","      # delay = np.random.randint(0,self.len-2)\n","      d_1 = np.random.randint(0,self.len/2)\n","      d_2 = np.random.randint(self.len/2,self.len-2)\n","      input[d_1:d_2] = 0 if(check) else 1\n","      #input[0:delay] = 0\n","      output = torch.zeros(self.len)\n","      \n","      for i in range(self.len):   \n","        self.phases += (2*np.pi*self.freqs/self.sample_rate)\n","        self.phases = self.phases * input[i]\n","        output[i] = torch.sum(harmonics*torch.sin(self.phases))*input[i]    \n","      return input, output"],"metadata":{"id":"w4w9PhXWsRCh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ec8bdb7"},"source":["Let's generate a dataset and plot its content."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56afb2bd"},"outputs":[],"source":["# Dataset configuration\n","period_len = 60\n","n_periods = 4\n","# Generate a distribution of harmonics\n","harmonics = torch.zeros(period_len//2)\n","harmonics[1] = 1\n","harmonics[2] = 1\n","harmonics[3] = 1\n","harmonics[10] = 1\n","# Normalize distribution\n","harmonics = harmonics/torch.sum(harmonics)\n","\n","# Create dataset\n","batch_size = 60\n","dataset = HarmonicSeriesDataset(harmonics,n_periods)\n","train_dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size)\n","\n","# Sample storage to plot\n","signal_len = len(train_dataloader)\n","print(period_len*n_periods)\n","print(signal_len)\n","\n","# Examples of dataset\n","samples = torch.zeros(batch_size,period_len*n_periods,2)\n","\n","samples[:,:,0],samples[:,:,1] = next(iter(train_dataloader))\n","\n","\n","print(\"Samples.shape:\",samples.shape)\n","for i in range(5):\n","  plt.plot(samples[i,:,0].detach().numpy())\n","  plt.plot(samples[i,:,1].detach().numpy())\n","  plt.title(\"Input and Output {}\".format(i))\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"9be3ea08"},"source":["# **Dataset Example.** \n","\n","Let's generate a dataset for the models to predict an output $A$ samples ahead."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0209b72"},"outputs":[],"source":["print(sample.shape)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(samples[0,:,:].detach().cpu().numpy())\n","# ax.plot(test_samples.view(-1).detach().cpu().numpy())\n","plt.title(\"Test Samples\")\n","plt.show()"]},{"cell_type":"markdown","source":["# **Gated Recurrent Unit (GRU)**"],"metadata":{"id":"dXBe9RfFjL1p"}},{"cell_type":"code","source":["class GRUmodel(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, num_layers=1):\n","    super(GRUmodel, self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_dim = hidden_dim\n","    # GRU (input)\n","    self.gru = nn.GRU(input_size, hidden_dim, num_layers=num_layers, batch_first=True)\n","    # Fully connected (output)\n","    self.lin = nn.Linear(hidden_dim, output_size)\n","    \n","  # Forward method\n","  def forward(self, seq):\n","\n","    input = seq  # input.shape = (N,L,input_size)\n","    \n","    out, hidden = self.gru(input) # out.shape = (L,hidden_dim)...hidden.shape = (num_layers, hidden_dim)\n","    out = self.lin(out) # out.shape = (1,1)\n","    return out\n"],"metadata":{"id":"H6GvDuLujSN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gru_evaluate_on_data(net, eval_input, target, device, plot=False):\n","\n","  L = target.shape[1] # sequence length\n","  batch_size = target.shape[0] # batch size\n","  random = np.random.randint(0,batch_size-2)\n","  target = target[random,:,:].unsqueeze(0).to(device) # ([N,L,1])\n","  # seq = torch.ones([batch_size,L,1]).to(device) # ([N,L,1])\n","  seq = eval_input[random,:,:].unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    pred = net(seq)\n","      # Calculate evaluation loss\n","  eval_loss = torch.sum(torch.abs(target-pred))\n","\n","  # Plotting results\n","  if(plot):\n","    fig, ax = plt.subplots()\n","    print(\"[TEST ON DATA] Eval loss {}\".format(eval_loss))\n","    ax.plot(seq[0,:,:].detach().numpy())\n","    ax.plot(target[0,:,:].detach().numpy())\n","    ax.plot(pred[0,:,:].detach().numpy())\n","    plt.show()\n","\n","  return eval_loss\n","  \n","def gru_train(net, epochs, train_dataloader, device):\n","  \n","  net.train()\n","\n","  # Define Loss, Optimizer, ecc.\n","  criterion = nn.L1Loss()\n","  optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","  best_eval_loss = np.inf\n","\n","  # target = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1])\n","  # train = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1]) \n","  # L = target.shape[1] # sequence length\n","  # n_batches = target.shape[0] # batch size\n","  epochs_loss = np.zeros(epochs)\n","\n","  for epoch in range(epochs): \n","    optimizer.zero_grad()\n","    running_loss = 0.0\n","\n","    for i,sample in enumerate(train_dataloader):\n","      target,seq = sample\n","      target = target.unsqueeze(2).to(device)\n","      seq = seq.unsqueeze(2).to(device)\n","      prediction = net(seq)\n","      loss = criterion(prediction, target) # Calculate loss\n","      loss.backward() # Backpropagation and calculates gradients\n","      optimizer.step() # Updates the weights\n","    # Print statistics\n","    running_loss += loss.item() # To calculate epochs' mean loss\n","    plot = True if (epoch%(epochs/16)==0) else False\n","    eval_loss = gru_evaluate_on_data(net, seq, target, device, plot=plot)\n","    \n","    epochs_loss[epoch] = eval_loss # For plotting loss during epochs\n","\n","    if eval_loss < best_eval_loss:\n","      best_eval_loss = eval_loss\n","      torch.save(net.state_dict(), 'best_gru.pt')\n","\n","    if (epoch%(epochs/20) == 0):\n","        print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n","        print(\"Train Loss: {:.4f} - Best Eval {:.4f}\".format(running_loss, best_eval_loss))\n","    \n","    running_loss = 0.0\n","\n","  print(\"---------- FINISHED TRAINING ----------\")\n","\n","  # Print Eval Loss\n","  x_ = np.linspace(0, epochs-1, epochs)\n","  y_ = epochs_loss\n","  yhat_ = signal.savgol_filter(y_, 101, 3) # Savitzky-Golay filter for smoothing\n","\n","  fig, ax = plt.subplots()\n","  ax.plot(x_, y_)\n","  ax.plot(x_, yhat_)\n","  ax.set_xlabel('Epochs')\n","  ax.set_ylabel('Eval Loss') \n","  # ax.grid(True) \n","  plt.show()"],"metadata":{"id":"us6NDKk_zbPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_test_GRU(hidden_size, n_hidden_layers, train_dataloader, target, epochs, device):\n","  #train_len = train_data.size()[2]\n","\n","  net = GRUmodel(1,1,hidden_size, n_hidden_layers)\n","  net = net.to(device)\n","\n","  model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n","  params = sum([np.prod(p.size()) for p in model_parameters])\n","  print(\"[INFO] Number of parameters: {}\".format(params))\n","  \n","  # TRAINING\n","  gru_train(net, epochs, train_data, device)\n","\n","  # TEST\n","  net.load_state_dict(torch.load('best_gru.pt'))  \n","  net.eval()\n","  input,target = next(iter(train_dataloader))\n","  gru_evaluate_on_data(net, input, target, device, plot=True)\n","\n","  return net"],"metadata":{"id":"9IfZZfcnFhZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GRUnet = train_and_test_GRU(hidden_size=64, n_hidden_layers=1, train_data=train_dataloader, target=train_dataloader, epochs=5000, device=dev)"],"metadata":{"id":"q2m9ScccH6Hx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Testing Trained GRUnet**"],"metadata":{"id":"ZU7wXH--2tpZ"}},{"cell_type":"code","source":["seq = torch.ones(1,960,1)\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()\n","\n","seq = torch.ones(1,960,1)\n","seq[:,55:120,:] = 0\n","seq[:,360:480,:] = 0\n","seq[:,720:959,:] = 0\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()"],"metadata":{"id":"Zg9nEOnczcCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq = torch.ones(1,2048,1)\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()\n","\n","seq = torch.ones(1,2048,1)\n","seq[:,120:240,:] = 1\n","seq[:,1024:2000,:] = 1\n","signal = GRUnet(seq)\n","\n","plt.plot(seq[0,:,:].detach().numpy())\n","plt.plot(signal[0,:,:].detach().numpy())\n","plt.show()"],"metadata":{"id":"BaWCDrU5-KI1"},"execution_count":null,"outputs":[]}]}