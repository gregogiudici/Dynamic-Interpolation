{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6103,"status":"ok","timestamp":1675935294270,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"sX_TCZCxYvol","outputId":"e67e4964-70b7-4e4a-e588-a4dd76ea2aff"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy import signal\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","import random\n","\n","if torch.cuda.is_available():\n","  dev = 'cuda'\n","  print(\"Cuda avaiable. Device used to train the model:\", dev)\n","else: \n","  dev = 'cpu'\n","  print(\"Cuda not avaiable. Device used to train the model:\", dev)\n"]},{"cell_type":"markdown","metadata":{"id":"d7b5d1ab"},"source":["# **A harmonic series dataset**\n","\n","This dataset generates an input signal and an output signal, given a harmonic distribution and a number of cycles we want to compute."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675935341525,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"w4w9PhXWsRCh"},"outputs":[],"source":["# Multishape dataset\n","class HarmonicSeriesDataset(Dataset):\n","    \"\"\" Class to generate an harmonic series dataset (input+output).\n","    Args:\n","    harmonics = harmonic distribution of output signal\n","    shape = 'step' or 'ramp'\n","    amplitudes = set of max amplitudes of the signals of the dataset\n","    n_periods = number of periods to compute\n","    \"\"\"\n","    \n","    def __init__(self, harmonics, shape='step', amplitudes=[0.25, 0.5, 0.75, 1.0], n_periods=1):\n","        self.harmonics = torch.tensor(harmonics)\n","        self.shape = shape if shape in ['step', 'ramp'] else 'step'\n","        self.len = n_periods*2*harmonics.size()[0]\n","        self.amplitudes = amplitudes\n","        self.sample_rate = 2*harmonics.size()[0]\n","        self.sample_time = 1/(2*harmonics.size()[0])\n","        self.n_freqs = harmonics.size()[0]\n","        self.phases = torch.zeros(self.n_freqs)\n","        self.freqs = torch.linspace(start=0, end=self.n_freqs-1, steps=self.n_freqs)\n","    \n","    def __len__(self):\n","        return 128\n","\n","    def __getitem__(self, idx):\n","      \n","      self.phases[:] = 0\n","      amp = np.random.choice(self.amplitudes)\n","      d_1 = np.random.randint(0,self.len/2)\n","      d_2 = np.random.randint(self.len/2,self.len-2)\n","      check = np.random.choice([True,False])\n","      on_off = torch.ones(self.len) if(check) else torch.zeros(self.len)\n","      on_off[d_1:d_2] = 0 if(check) else 1\n","      \n","      # Define Input\n","      #if self.shape == 'random':\n","      #  input = torch.rand(self.len)*amp if(check) else torch.zeros(self.len)\n","      #  input[d_1:d_2] = 0 if(check) else torch.rand(d_2-d_1)*amp\n","      #else:\n","      #  input = torch.ones(self.len)*amp if(check) else torch.zeros(self.len)\n","      #  input[d_1:d_2] = 0 if(check) else amp\n","      \n","      input = torch.ones(self.len)*amp if(check) else torch.zeros(self.len)\n","      input[d_1:d_2] = 0 if(check) else amp\n","      # Define Outpu\n","      output = torch.zeros(self.len)\n","        \n","      for i in range(self.len): \n","        \n","        if self.shape == 'ramp':\n","          if i == 0:\n","            input[i] = self.sample_time if on_off[i] else 0\n","          else:\n","            input[i] = input[i-1] + self.sample_time if on_off[i] else 0\n","          \n","        # Clip input from 0 to amp\n","        input[i] = input[i].clip(0,amp)  \n","        \n","        self.phases += (2*np.pi*self.freqs/self.sample_rate)\n","        self.phases = self.phases * on_off[i]\n","        output[i] = torch.sum(self.harmonics*torch.sin(self.phases))*input[i]    \n","      \n","      return input, output"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6ec8bdb7"},"source":["# Dataset\n","Let's generate a dataset and plot its content."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3666,"status":"ok","timestamp":1675935348294,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"56afb2bd","outputId":"2e653f94-5c01-4c5e-c092-a9e26990828c"},"outputs":[],"source":["# Dataset configuration\n","period_len = 60\n","n_periods = 4\n","# Generate a distribution of harmonics\n","harmonics = torch.zeros(period_len//2)\n","harmonics[1] = 1\n","harmonics[2] = 1\n","harmonics[3] = 1\n","harmonics[10] = 1\n","# Normalize distribution\n","harmonics = harmonics/torch.sum(harmonics)\n","\n","# Create dataset\n","batch_size = 64\n","amplitudes = np.linspace(0,1,period_len)\n","train_dataset = HarmonicSeriesDataset(harmonics=harmonics, shape='step', amplitudes=amplitudes, n_periods=n_periods)\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n","\n","# Sample storage to plot\n","signal_len = len(train_dataloader)\n","print(period_len*n_periods)\n","print(signal_len)\n","\n","# Examples of dataset\n","train_samples = torch.zeros(batch_size,period_len*n_periods,2)\n","\n","train_samples[:,:,0], train_samples[:,:,1] = next(iter(train_dataloader))\n","\n","print(\"Samples.shape:\", train_samples.shape)\n","for i in range(5):\n","  plt.plot(train_samples[i,:,0].detach().cpu().numpy())\n","  plt.plot(train_samples[i,:,1].detach().cpu().numpy())\n","  plt.title(\"TRAINING SAMPLES: Input and Output {}\".format(i))\n","  plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dXBe9RfFjL1p"},"source":["# **Gated Recurrent Unit (GRU)**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":995,"status":"ok","timestamp":1675936246408,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"H6GvDuLujSN3"},"outputs":[],"source":["class GRUmodel(nn.Module):\n","  def __init__(self, input_size, output_size, hidden_dim, num_layers=1):\n","    super(GRUmodel, self).__init__()\n","    self.num_layers = num_layers\n","    self.hidden_dim = hidden_dim\n","    # GRU (input)\n","    self.gru = nn.GRU(input_size, hidden_dim, num_layers=num_layers, batch_first=True)\n","    # Fully connected (output)\n","    self.lin = nn.Linear(hidden_dim, output_size)\n","    \n","  # Forward method\n","  def forward(self, seq):\n","\n","    input = seq  # input.shape = (batch_size, sequence_length ,input_size)\n","  \n","    out, hidden = self.gru(input) # out.shape = (sequence_length, hidden_dim) # hidden.shape = (num_layers, hidden_dim)\n","    out = self.lin(out) # out.shape = (sequence_length,1)\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1675936948647,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"us6NDKk_zbPL"},"outputs":[],"source":["def gru_evaluate_on_data(net, eval_input, target, device, plot=False):\n","\n","  L = target.shape[1] # sequence length\n","  batch_size = target.shape[0] # batch size\n","  random = np.random.randint(0,batch_size-2)\n","  target = target[random,:,:].unsqueeze(0).to(device) # ([N,L,1])\n","  # seq = torch.ones([batch_size,L,1]).to(device) # ([N,L,1])\n","  seq = eval_input[random,:,:].unsqueeze(0).to(device)\n","\n","  with torch.no_grad():\n","    pred = net(seq)\n","      # Calculate evaluation loss\n","  eval_loss = torch.sum(torch.abs(target-pred))\n","\n","  # Plotting results\n","  if(plot):\n","    fig, ax = plt.subplots()\n","    print(\"[TEST ON DATA] Eval loss {}\".format(eval_loss))\n","    ax.plot(seq[0,:,:].detach().cpu().numpy())\n","    ax.plot(target[0,:,:].detach().cpu().numpy())\n","    ax.plot(pred[0,:,:].detach().cpu().numpy())\n","    plt.show()\n","\n","  return eval_loss\n","  \n","def gru_train(net, epochs, train_dataloader, device, save_state='best_gru.pt'):\n","  \n","  net.train()\n","\n","  # Define Loss, Optimizer, ecc.\n","  criterion = nn.L1Loss()\n","  optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","  best_eval_loss = np.inf\n","\n","  # target = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1])\n","  # train = train_samples[:,:,1].unsqueeze(2).to(device) #([N,L,1]) \n","  # L = target.shape[1] # sequence length\n","  # n_batches = target.shape[0] # batch size\n","  epochs_loss = np.zeros(epochs)\n","\n","  for epoch in range(epochs): \n","    optimizer.zero_grad()\n","    running_loss = 0.0\n","\n","    for i,sample in enumerate(train_dataloader):\n","      seq,target = sample\n","      target = target.unsqueeze(2).to(device)\n","      seq = seq.unsqueeze(2).to(device)\n","      prediction = net(seq)\n","      loss = criterion(prediction, target) # Calculate loss\n","      loss.backward() # Backpropagation and calculates gradients\n","      optimizer.step() # Updates the weights\n","    # Print statistics\n","    running_loss += loss.item() # To calculate epochs' mean loss\n","    plot = True if (epoch%(epochs/16)==0) else False\n","    eval_loss = gru_evaluate_on_data(net, seq, target, device, plot=plot)\n","    \n","    epochs_loss[epoch] = eval_loss # For plotting loss during epochs\n","\n","    if eval_loss < best_eval_loss:\n","      best_eval_loss = eval_loss\n","      torch.save(net.state_dict(), save_state)\n","\n","    if (epoch%(epochs/20) == 0):\n","        print('Epoch: {}/{} .............'.format(epoch, epochs), end=' ')\n","        print(\"Train Loss: {:.4f} - Best Eval {:.4f}\".format(running_loss, best_eval_loss))\n","    \n","    running_loss = 0.0\n","\n","  print(\"---------- FINISHED TRAINING ----------\")\n","\n","  # Print Eval Loss\n","  x_ = np.linspace(0, epochs-1, epochs)\n","  y_ = epochs_loss\n","  yhat_ = signal.savgol_filter(y_, 101, 3) # Savitzky-Golay filter for smoothing\n","\n","  fig, ax = plt.subplots()\n","  ax.plot(x_, y_)\n","  ax.plot(x_, yhat_)\n","  ax.set_xlabel('Epochs')\n","  ax.set_ylabel('Eval Loss') \n","  # ax.grid(True) \n","  plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# **Training GRUnet**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":306,"status":"ok","timestamp":1675936955037,"user":{"displayName":"Gregorio Andrea Giudici","userId":"03087335526931147632"},"user_tz":-60},"id":"9IfZZfcnFhZU"},"outputs":[],"source":["def train_and_test_GRU(hidden_size, n_hidden_layers, train_dataloader, target, epochs, device, save_state='best_gru.pt'):\n","  #train_len = train_data.size()[2]\n","\n","  net = GRUmodel(1,1,hidden_size, n_hidden_layers)\n","  net = net.to(device)\n","\n","  model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n","  params = sum([np.prod(p.size()) for p in model_parameters])\n","  print(\"[INFO] Number of parameters: {}\".format(params))\n","  \n","  # TRAINING\n","  gru_train(net, epochs, train_dataloader, device, save_state)\n","\n","  # TEST\n","  net.load_state_dict(torch.load(save_state))  \n","  net.eval()\n","  input,target = next(iter(train_dataloader))\n","  input = input.unsqueeze(2)\n","  target = target.unsqueeze(2)\n","  gru_evaluate_on_data(net, input, target, device, plot=True)\n","\n","  return net"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":338},"id":"q2m9ScccH6Hx","outputId":"21c237d4-5e81-43f9-f9ff-d35e56d9b989"},"outputs":[],"source":["GRUnet = train_and_test_GRU(hidden_size=64, n_hidden_layers=1, train_dataloader=train_dataloader, target=train_dataloader, epochs=5000, device=dev)"]},{"cell_type":"markdown","metadata":{"id":"ZU7wXH--2tpZ"},"source":["# **Testing Trained GRUnet**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load Pre-trained Net for Testing [Optional]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["GRUnet = GRUmodel(1,1,64,1)\n","GRUnet = GRUnet.to(dev)\n","GRUnet.load_state_dict(torch.load('./nn_saved_states/multi_1402_dot25.pt'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Testing with step/square input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zg9nEOnczcCu"},"outputs":[],"source":["# Testing with a random input+target from dataloader\n","\n","seq, target = next(iter(train_dataloader))\n","batch_size = target.shape[0] # batch size\n","random = np.random.randint(0,batch_size-2)\n","\n","seq = seq[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","target = target[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","\n","# Calculate Output\n","GRUnet.eval()\n","out = GRUnet(seq)\n","\n","eval_loss =torch.sum(torch.abs(target-out))\n","print(\"[TEST ON STEP] Eval loss {}\".format(eval_loss))\n","\n","plt.plot(seq[0,:,:].detach().cpu().numpy())\n","plt.plot(target[0,:,:].detach().cpu().numpy())\n","plt.plot(out[0,:,:].detach().cpu().numpy())\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Testing with ramp input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaWCDrU5-KI1"},"outputs":[],"source":["# Testing with a new dataset with amplitudes different from training dataset\n","# amplitudes = [float(input(\"Choose input amplitude for testing dataset: \"))]\n","amplitudes = [0.2, 0.4, 0.6, 0.8]\n","test_dataset = HarmonicSeriesDataset(harmonics=harmonics, shape='ramp', n_periods=n_periods, amplitudes=amplitudes)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n","\n","for i in range(100):\n","    seq, target = next(iter(test_dataloader))\n","    seq = seq[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","    target = target[random,:].unsqueeze(0).unsqueeze(2).to(dev)\n","\n","    # Calculate Output\n","    out = GRUnet(seq)\n","    \n","    # Calculate Eval Loss\n","    eval_loss =torch.sum(torch.abs(target-out))\n","    print(\"[TEST {} with RAMP] Eval loss {}\".format(i,eval_loss))\n","    \n","    if eval_loss <= 5.0:\n","        plt.plot(seq[0,:,:].detach().cpu().numpy())\n","        plt.plot(target[0,:,:].detach().cpu().numpy())\n","        plt.plot(out[0,:,:].detach().cpu().numpy())\n","        plt.show()    \n","\n","    elif i%10==0:\n","        plt.plot(seq[0,:,:].detach().cpu().numpy())\n","        plt.plot(target[0,:,:].detach().cpu().numpy())\n","        plt.plot(out[0,:,:].detach().cpu().numpy())\n","        plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMoZ/LHpsKQIiI6NTa/WMmO","provenance":[]},"kernelspec":{"display_name":"myenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"51a1e27a7986eee058d319d028d75df63f805ad76db200a802ec4ff9ece56162"}}},"nbformat":4,"nbformat_minor":0}
